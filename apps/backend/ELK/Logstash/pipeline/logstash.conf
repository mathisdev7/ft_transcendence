input {
  beats {
    port => 5044
  }

  tcp {
    port => 5000
    codec => json { target => "event" }
  }

  http {
    port => 5001
     codec => json { target => "event" }
  }
}

filter {
  # Add service field from labels or parsed data
  if [fields][service] {
    mutate {
      add_field => { "service_name" => "%{[fields][service]}" }
    }
  } else if [service] {
    mutate {
      add_field => { "service_name" => "%{service}" }
    }
  }

  # Parse message if it's JSON
  if [message] and [message] =~ /^\s*\{.*\}\s*$/ {
    json {
      source => "message"
      target => "parsed"
    }

    # Move parsed fields to root level only if JSON parsing succeeded
    if "_jsonparsefailure" not in [tags] and [parsed] {
      ruby {
        code => "
          parsed = event.get('parsed')
          if parsed.is_a?(Hash)
            parsed.each { |k, v| event.set(k, v) }
            event.remove('parsed')
          end
        "
      }
    }
  }

  # Handle timestamp field
  if [@timestamp] {
    date {
      match => [ "@timestamp", "ISO8601" ]
    }
  } else if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }

  # Add environment and service metadata
  mutate {
    add_field => {
      "[@metadata][index_name]" => "logstash-%{+YYYY.MM.dd}"
    }
  }

  # Clean up unnecessary fields
  mutate {
    remove_field => [ "agent", "ecs", "host", "input", "headers" ]
  }
}

output {
	elasticsearch {
		hosts => ["${ELASTICSEARCH_HOSTS}"]
		user => "${ELASTICSEARCH_USERNAME}"
		password => "${ELASTICSEARCH_PASSWORD}"
		index => "%{[@metadata][index_name]}"
		ssl_enabled => true
		ssl_verification_mode => full
		ssl_certificate_authorities => ["/usr/share/logstash/config/certs/ca-cert.pem"]
	}

  stdout {
    codec => rubydebug
  }
}
